"""
FinDistill Multi-Format Exporter

Exports normalized financial data to:
- JSONL: For LLM fine-tuning
- Markdown: For RAG systems
- Parquet: For analytics (columnar storage)
- HDF5: For large-scale numerical/time-series data
"""

import json
from typing import Dict, Any
from datetime import datetime

class DataExporter:
    """Exports financial data to various formats for AI training."""
    
    def to_jsonl(self, data: Dict[str, Any]) -> str:
        """
        Convert to JSONL format exclusively using reasoning_qa.
        Surgical removal: legacy short-form logic (Row 2+) removed.
        """
        # Note: reasoning_qa already contains summary and trend pairs in 4-step CoT format.
        reasoning_qa = data.get("reasoning_qa", [])
        
        # If the backend engine provided JSONL data directly (with Poison Pill already applied), reuse it.
        # This occurs in the v11.5 strict pipeline.
        if "jsonl_data" in data and data["jsonl_data"]:
            return "\n".join(data["jsonl_data"])
            
        if not reasoning_qa:
            # STOP EXECUTION if no data is present. Do not create 0-byte or empty status files.
            logger.error("CRITICAL: reasoning_qa is empty. Aborting export.")
            raise ValueError("CRITICAL ERROR: Reasoning QA list is empty. Engine failed to generate data.")

        # Fallback for data structures without pre-generated JSONL
        lines = []
        for qa in reasoning_qa:
            entry = {
                "instruction": qa.get("question", "Analyze the financial data."),
                "input": data.get("title", "Financial Document"),
                "output": qa.get("response", ""),
                "metadata": data.get("metadata", {})
            }
            lines.append(json.dumps(entry, ensure_ascii=False))
            
        # Final check: Double validation
        if not lines:
             raise ValueError("CRITICAL ERROR: JSONL line generation failed despite presence of reasoning_qa.")

        # EXPLICIT CONFIRMATION LOG
        print(f"V11.5 DATA PIPE RESTORED: {len(lines)} ROWS WRITTEN")
        
        return "\n".join(lines)
    
    def to_markdown(self, data: Dict[str, Any]) -> str:
        """Convert to Markdown format for RAG systems."""
        md_lines = []
        
        # Title
        title = data.get("title", "Financial Document")
        md_lines.append(f"# {title}")
        md_lines.append("")
        
        # Metadata
        if "metadata" in data:
            md_lines.append("## Document Information")
            for key, value in data["metadata"].items():
                md_lines.append(f"- **{key}**: {value}")
            md_lines.append("")
        
        # Summary
        if "summary" in data:
            md_lines.append("## Summary")
            md_lines.append(data["summary"])
            md_lines.append("")
        
        # Key Metrics
        if "key_metrics" in data and data["key_metrics"]:
            md_lines.append("## Key Metrics")
            md_lines.append("")
            md_lines.append("| Metric | Value |")
            md_lines.append("|------|-----|")
            for metric, value in data["key_metrics"].items():
                md_lines.append(f"| {metric} | {value} |")
            md_lines.append("")
        
        # Tables
        for i, table in enumerate(data.get("tables", []), 1):
            table_name = table.get("name", f"Table {i}")
            headers = table.get("headers", [])
            rows = table.get("rows", [])
            
            md_lines.append(f"## {table_name}")
            md_lines.append("")
            
            if headers:
                # Sanitized headers
                safe_headers = [str(h).replace("|", "\\|") for h in headers]
                md_lines.append("| " + " | ".join(safe_headers) + " |")
                md_lines.append("|" + "|".join(["---"] * len(headers)) + "|")
                
                for row in rows:
                    padded_row = list(row) + [""] * (len(headers) - len(row))
                    safe_row = [str(v).replace("|", "\\|") for v in padded_row[:len(headers)]]
                    md_lines.append("| " + " | ".join(safe_row) + " |")
            
            md_lines.append("")
        
        # Footer
        md_lines.append("---")
        md_lines.append(f"*Generated by FinDistill at {datetime.now().isoformat()}*")
        
        return "\n".join(md_lines)
    
    def to_parquet(self, data: Dict[str, Any]) -> bytes:
        """
        Convert to Parquet format.
        Warning: This requires pandas/pyarrow which are not installed in serverless mode to save size.
        Will raise an error if called.
        """
        try:
            import pandas as pd
            import pyarrow as pa
            import pyarrow.parquet as pq
            import io
            
            # Implementation if libraries exist
            dfs = []
            for table in data.get("tables", []):
                table_name = table.get("name", "Unknown")
                headers = table.get("headers", [])
                rows = table.get("rows", [])
                
                if headers and rows:
                    df = pd.DataFrame(rows, columns=headers)
                    df["_source_table"] = table_name
                    dfs.append(df)
            
            if not dfs:
                 combined = pd.DataFrame({"info": ["no data"]})
            else:
                 combined = pd.concat(dfs, ignore_index=True)
            
            buffer = io.BytesIO()
            table = pa.Table.from_pandas(combined)
            pq.write_table(table, buffer, compression='snappy')
            return buffer.getvalue()
            
        except ImportError:
            raise RuntimeError("Parquet export not supported in serverless mode (requires pyarrow/pandas)")

    def to_hdf5(self, data: Dict[str, Any]) -> bytes:
        """
        Convert to HDF5 format for large-scale numerical and time-series data.
        Uses float64 precision for financial data accuracy.
        
        Warning: Requires h5py and numpy.
        """
        try:
            import h5py
            import numpy as np
            import io
            
            buffer = io.BytesIO()
            
            with h5py.File(buffer, 'w') as f:
                # Store metadata as attributes
                meta_group = f.create_group("metadata")
                meta_group.attrs["title"] = data.get("title", "Financial Document")
                meta_group.attrs["summary"] = data.get("summary", "")
                meta_group.attrs["created_at"] = datetime.now().isoformat()
                
                # Store key metrics
                if "key_metrics" in data and data["key_metrics"]:
                    metrics_group = f.create_group("key_metrics")
                    for key, value in data["key_metrics"].items():
                        # Try to convert to float64 for precision
                        try:
                            numeric_value = float(str(value).replace(",", "").replace("%", ""))
                            metrics_group.create_dataset(
                                key, 
                                data=np.array([numeric_value], dtype=np.float64)
                            )
                        except (ValueError, TypeError):
                            # Store as string if not numeric
                            metrics_group.attrs[key] = str(value)
                
                # Store tables
                tables_group = f.create_group("tables")
                for i, table in enumerate(data.get("tables", [])):
                    table_name = table.get("name", f"table_{i}")
                    # Clean table name for HDF5 compatibility
                    safe_name = "".join(c if c.isalnum() or c == "_" else "_" for c in table_name)
                    
                    table_group = tables_group.create_group(safe_name)
                    headers = table.get("headers", [])
                    rows = table.get("rows", [])
                    
                    # Store headers
                    if headers:
                        table_group.attrs["headers"] = json.dumps(headers, ensure_ascii=False)
                    
                    # Try to store as numeric array with float64 precision
                    if rows:
                        try:
                            # Attempt to convert to numeric (for financial data)
                            numeric_rows = []
                            for row in rows:
                                numeric_row = []
                                for val in row:
                                    try:
                                        # Clean and convert to float64
                                        clean_val = str(val).replace(",", "").replace("%", "").replace("$", "").replace("â‚©", "")
                                        numeric_row.append(float(clean_val))
                                    except (ValueError, TypeError):
                                        numeric_row.append(float('nan'))
                                numeric_rows.append(numeric_row)
                            
                            # Store as float64 array for precision
                            table_group.create_dataset(
                                "data",
                                data=np.array(numeric_rows, dtype=np.float64),
                                compression="gzip"
                            )
                        except Exception:
                            # Fallback: store as JSON string
                            table_group.attrs["data_json"] = json.dumps(rows, ensure_ascii=False)
            
            return buffer.getvalue()
            
        except ImportError:
            raise RuntimeError("HDF5 export not supported (requires h5py/numpy). Install with: pip install h5py numpy")

    def _table_to_text(self, table: Dict[str, Any]) -> str:
        """Convert a table to readable text format."""
        lines = []
        headers = table.get("headers", [])
        rows = table.get("rows", [])
        
        if headers:
            lines.append("Columns: " + ", ".join(str(h) for h in headers))
        
        for i, row in enumerate(rows[:5], 1):
            val_strs = [str(v) for v in row]
            lines.append(f"Row {i}: " + ", ".join(val_strs))
        
        if len(rows) > 5:
            lines.append(f"... and {len(rows) - 5} other rows")
        
        return "\n".join(lines)


# Singleton instance
exporter = DataExporter()

