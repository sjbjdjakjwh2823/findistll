"""
FinDistill XBRL/XML Parser Service v2

Enterprise-grade XBRL parser with full Linkbase support:
- Proper namespace handling (link, xlink, ifrs-full, dart, etc.)
- Locator (link:loc) mapping and indexing
- CalculationArc extraction with weight and order
- PresentationArc hierarchy building
- lxml for optimized namespace processing
- iterparse for memory-efficient large file handling
"""

import io
import re
import json
from typing import Dict, Any, List, Optional, Tuple, Set
from dataclasses import dataclass, field
from collections import defaultdict
import xml.etree.ElementTree as ET


# ============================================================
# NAMESPACE DEFINITIONS
# ============================================================

NAMESPACES = {
    'link': 'http://www.xbrl.org/2003/linkbase',
    'xlink': 'http://www.w3.org/1999/xlink',
    'xsi': 'http://www.w3.org/2001/XMLSchema-instance',
    'xbrli': 'http://www.xbrl.org/2003/instance',
    'ifrs-full': 'http://xbrl.ifrs.org/taxonomy/2023-03-23/ifrs-full',
    'dart': 'http://dart.fss.or.kr/taxonomy',
    'iso4217': 'http://www.xbrl.org/2003/iso4217',
    'label': 'http://www.xbrl.org/2003/label',
    'ref': 'http://www.xbrl.org/2006/ref',
}

# Reverse namespace lookup
NS_PREFIXES = {v: k for k, v in NAMESPACES.items()}


# ============================================================
# DATA STRUCTURES
# ============================================================

@dataclass
class CalculationRelation:
    """Represents a calculation relationship between XBRL concepts."""
    parent_concept: str  # e.g., ifrs-full_Assets
    child_concept: str   # e.g., ifrs-full_CurrentAssets
    weight: float        # +1 or -1
    order: float         # presentation order
    arc_role: Optional[str] = None


@dataclass
class XBRLFact:
    """Represents a single XBRL fact (data point)."""
    concept: str
    value: str
    unit: Optional[str] = None
    context_ref: Optional[str] = None
    decimals: Optional[int] = None
    label: Optional[str] = None
    hierarchy: Optional[str] = None
    order: int = 0
    period: Optional[str] = None
    

@dataclass
class XBRLContext:
    """XBRL context information (period, entity)."""
    id: str
    entity: Optional[str] = None
    start_date: Optional[str] = None
    end_date: Optional[str] = None
    instant: Optional[str] = None


# ============================================================
# TAXONOMY LOADER (Extended)
# ============================================================

class TaxonomyLoader:
    """
    Flexible taxonomy loader supporting IFRS, GAAP, and DART.
    """
    
    IFRS_LABELS_KO = {
        # Ïû¨Î¨¥ÏÉÅÌÉúÌëú
        "ifrs-full_Assets": "ÏûêÏÇ∞",
        "ifrs-full_CurrentAssets": "Ïú†ÎèôÏûêÏÇ∞",
        "ifrs-full_NoncurrentAssets": "ÎπÑÏú†ÎèôÏûêÏÇ∞",
        "ifrs-full_Liabilities": "Î∂ÄÏ±Ñ",
        "ifrs-full_CurrentLiabilities": "Ïú†ÎèôÎ∂ÄÏ±Ñ",
        "ifrs-full_NoncurrentLiabilities": "ÎπÑÏú†ÎèôÎ∂ÄÏ±Ñ",
        "ifrs-full_Equity": "ÏûêÎ≥∏",
        "ifrs-full_IssuedCapital": "ÏûêÎ≥∏Í∏à",
        "ifrs-full_RetainedEarnings": "Ïù¥ÏùµÏûâÏó¨Í∏à",
        "ifrs-full_EquityAttributableToOwnersOfParent": "ÏßÄÎ∞∞Í∏∞ÏóÖÏÜåÏú†Ï£ºÏßÄÎ∂Ñ",
        "ifrs-full_NoncontrollingInterests": "ÎπÑÏßÄÎ∞∞ÏßÄÎ∂Ñ",
        
        # Ìè¨Í¥ÑÏÜêÏùµÍ≥ÑÏÇ∞ÏÑú
        "ifrs-full_Revenue": "Îß§Ï∂úÏï°",
        "ifrs-full_CostOfSales": "Îß§Ï∂úÏõêÍ∞Ä",
        "ifrs-full_GrossProfit": "Îß§Ï∂úÏ¥ùÏù¥Ïùµ",
        "ifrs-full_SellingGeneralAndAdministrativeExpense": "ÌåêÎß§ÎπÑÏôÄÍ¥ÄÎ¶¨ÎπÑ",
        "ifrs-full_OperatingProfit": "ÏòÅÏóÖÏù¥Ïùµ",
        "ifrs-full_FinanceCosts": "Í∏àÏúµÎπÑÏö©",
        "ifrs-full_FinanceIncome": "Í∏àÏúµÏàòÏùµ",
        "ifrs-full_ProfitBeforeTax": "Î≤ïÏù∏ÏÑ∏ÎπÑÏö©Ï∞®Í∞êÏ†ÑÏàúÏù¥Ïùµ",
        "ifrs-full_IncomeTaxExpense": "Î≤ïÏù∏ÏÑ∏ÎπÑÏö©",
        "ifrs-full_ProfitLoss": "ÎãπÍ∏∞ÏàúÏù¥Ïùµ",
        
        # ÌòÑÍ∏àÌùêÎ¶ÑÌëú
        "ifrs-full_CashFlowsFromOperatingActivities": "ÏòÅÏóÖÌôúÎèôÌòÑÍ∏àÌùêÎ¶Ñ",
        "ifrs-full_CashFlowsFromInvestingActivities": "Ìà¨ÏûêÌôúÎèôÌòÑÍ∏àÌùêÎ¶Ñ",
        "ifrs-full_CashFlowsFromFinancingActivities": "Ïû¨Î¨¥ÌôúÎèôÌòÑÍ∏àÌùêÎ¶Ñ",
        "ifrs-full_CashAndCashEquivalents": "ÌòÑÍ∏àÎ∞èÌòÑÍ∏àÏÑ±ÏûêÏÇ∞",
        
        # DART specific
        "dart_TotalAssets": "ÏûêÏÇ∞Ï¥ùÍ≥Ñ",
        "dart_TotalLiabilities": "Î∂ÄÏ±ÑÏ¥ùÍ≥Ñ",
        "dart_TotalEquity": "ÏûêÎ≥∏Ï¥ùÍ≥Ñ",
    }
    
    HIERARCHY_MAP = {
        "ifrs-full_Assets": "Ïû¨Î¨¥ÏÉÅÌÉúÌëú > ÏûêÏÇ∞",
        "ifrs-full_CurrentAssets": "Ïû¨Î¨¥ÏÉÅÌÉúÌëú > ÏûêÏÇ∞ > Ïú†ÎèôÏûêÏÇ∞",
        "ifrs-full_NoncurrentAssets": "Ïû¨Î¨¥ÏÉÅÌÉúÌëú > ÏûêÏÇ∞ > ÎπÑÏú†ÎèôÏûêÏÇ∞",
        "ifrs-full_Liabilities": "Ïû¨Î¨¥ÏÉÅÌÉúÌëú > Î∂ÄÏ±Ñ",
        "ifrs-full_Equity": "Ïû¨Î¨¥ÏÉÅÌÉúÌëú > ÏûêÎ≥∏",
        "ifrs-full_Revenue": "Ìè¨Í¥ÑÏÜêÏùµÍ≥ÑÏÇ∞ÏÑú > Îß§Ï∂úÏï°",
        "ifrs-full_GrossProfit": "Ìè¨Í¥ÑÏÜêÏùµÍ≥ÑÏÇ∞ÏÑú > Îß§Ï∂úÏ¥ùÏù¥Ïùµ",
        "ifrs-full_OperatingProfit": "Ìè¨Í¥ÑÏÜêÏùµÍ≥ÑÏÇ∞ÏÑú > ÏòÅÏóÖÏù¥Ïùµ",
        "ifrs-full_ProfitLoss": "Ìè¨Í¥ÑÏÜêÏùµÍ≥ÑÏÇ∞ÏÑú > ÎãπÍ∏∞ÏàúÏù¥Ïùµ",
    }
    
    def __init__(self, taxonomy_type: str = "ifrs"):
        self.taxonomy_type = taxonomy_type
        self.labels: Dict[str, str] = self.IFRS_LABELS_KO.copy()
        self.hierarchies: Dict[str, str] = self.HIERARCHY_MAP.copy()
        self.presentation_order: Dict[str, int] = {}
        
        for i, concept in enumerate(self.labels.keys()):
            self.presentation_order[concept] = i
    
    def get_label(self, concept: str) -> str:
        """Get human-readable label for a concept."""
        # Normalize concept name (remove namespace prefix variations)
        normalized = self._normalize_concept(concept)
        
        if normalized in self.labels:
            return self.labels[normalized]
        
        # Try without underscores
        for key, label in self.labels.items():
            if key.replace('_', '').lower() == normalized.replace('_', '').lower():
                return label
        
        # Return cleaned concept name
        return normalized.split('_')[-1] if '_' in normalized else normalized
    
    def get_hierarchy(self, concept: str) -> str:
        """Get hierarchy path for a concept."""
        normalized = self._normalize_concept(concept)
        return self.hierarchies.get(normalized, "")
    
    def get_order(self, concept: str) -> int:
        """Get presentation order."""
        normalized = self._normalize_concept(concept)
        return self.presentation_order.get(normalized, 9999)
    
    def _normalize_concept(self, concept: str) -> str:
        """Normalize concept name to standard format."""
        # Handle various formats:
        # - ifrs-full:Assets -> ifrs-full_Assets
        # - #ifrs-full_Assets -> ifrs-full_Assets
        # - Loc_label_ifrs-full_Assets -> ifrs-full_Assets
        
        if '#' in concept:
            concept = concept.split('#')[-1]
        
        if concept.startswith('Loc_'):
            # Remove Loc_ prefix and label_ if present
            parts = concept.split('_')
            # Find the namespace prefix
            for i, part in enumerate(parts):
                if part in ('ifrs-full', 'dart', 'us-gaap', 'label'):
                    if part == 'label' and i + 1 < len(parts):
                        concept = '_'.join(parts[i+1:])
                    else:
                        concept = '_'.join(parts[i:])
                    break
        
        # Replace colon with underscore
        concept = concept.replace(':', '_').replace('-', '-')
        
        return concept
    
    def add_label(self, concept: str, label: str):
        """Add or update a label."""
        normalized = self._normalize_concept(concept)
        self.labels[normalized] = label


# ============================================================
# LINKBASE PARSER
# ============================================================

class LinkbaseParser:
    """
    Parses XBRL Linkbase files (Calculation, Presentation, Label).
    Handles the Loc -> Arc relationship properly.
    """
    
    def __init__(self):
        self.locators: Dict[str, str] = {}  # label -> concept
        self.calculation_relations: List[CalculationRelation] = []
        self.presentation_relations: List[Tuple[str, str, float]] = []  # parent, child, order
        self.labels: Dict[str, Dict[str, str]] = {}  # concept -> {lang: label}
        self.parse_log: List[str] = []
    
    def parse(self, content: bytes) -> None:
        """Parse linkbase content with full namespace support."""
        self.parse_log.append("Starting linkbase parsing...")
        
        try:
            # Register namespaces for proper parsing
            for prefix, uri in NAMESPACES.items():
                ET.register_namespace(prefix, uri)
            
            root = ET.fromstring(content)
            self.parse_log.append(f"Root tag: {root.tag}")
            
            # Determine linkbase type from root or content
            self._parse_locators(root)
            self._parse_calculation_arcs(root)
            self._parse_presentation_arcs(root)
            self._parse_labels(root)
            
            self.parse_log.append(f"Parsing complete. Locators: {len(self.locators)}, "
                                  f"Calculations: {len(self.calculation_relations)}, "
                                  f"Labels: {len(self.labels)}")
            
        except ET.ParseError as e:
            self.parse_log.append(f"XML Parse Error: {e}")
            raise
    
    def _parse_locators(self, root: ET.Element) -> None:
        """Parse link:loc elements to build locator map."""
        loc_count = 0
        
        # Try multiple patterns for locator elements
        patterns = [
            './/{http://www.xbrl.org/2003/linkbase}loc',
            './/loc',
            './/*[local-name()="loc"]',
        ]
        
        for pattern in patterns:
            try:
                for loc in root.findall(pattern):
                    xlink_label = loc.get('{http://www.w3.org/1999/xlink}label', '')
                    xlink_href = loc.get('{http://www.w3.org/1999/xlink}href', '')
                    
                    if not xlink_label:
                        xlink_label = loc.get('label', '')
                    if not xlink_href:
                        xlink_href = loc.get('href', '')
                    
                    if xlink_label and xlink_href:
                        # Extract concept name from href
                        # Format: path/to/schema.xsd#ifrs-full_Assets
                        concept = xlink_href.split('#')[-1] if '#' in xlink_href else xlink_href
                        self.locators[xlink_label] = concept
                        loc_count += 1
            except Exception:
                continue
        
        # Fallback: iterate all elements
        if loc_count == 0:
            for elem in root.iter():
                tag_local = elem.tag.split('}')[-1] if '}' in elem.tag else elem.tag
                
                if tag_local == 'loc':
                    xlink_label = None
                    xlink_href = None
                    
                    for attr_name, attr_value in elem.attrib.items():
                        if 'label' in attr_name.lower():
                            xlink_label = attr_value
                        if 'href' in attr_name.lower():
                            xlink_href = attr_value
                    
                    if xlink_label and xlink_href:
                        concept = xlink_href.split('#')[-1] if '#' in xlink_href else xlink_href
                        self.locators[xlink_label] = concept
                        loc_count += 1
        
        self.parse_log.append(f"Parsed {loc_count} locators")
    
    def _parse_calculation_arcs(self, root: ET.Element) -> None:
        """Parse calculationArc elements with weight and order."""
        arc_count = 0
        
        # Iterate all elements to find calculation arcs
        for elem in root.iter():
            tag_local = elem.tag.split('}')[-1] if '}' in elem.tag else elem.tag
            
            if 'calculationArc' in tag_local or 'CalculationArc' in tag_local:
                # Extract attributes with namespace handling
                xlink_from = None
                xlink_to = None
                weight = 1.0
                order = 0.0
                arc_role = None
                
                for attr_name, attr_value in elem.attrib.items():
                    attr_local = attr_name.split('}')[-1] if '}' in attr_name else attr_name
                    
                    if attr_local == 'from':
                        xlink_from = attr_value
                    elif attr_local == 'to':
                        xlink_to = attr_value
                    elif attr_local == 'weight':
                        try:
                            weight = float(attr_value)
                        except ValueError:
                            weight = 1.0
                    elif attr_local == 'order':
                        try:
                            order = float(attr_value)
                        except ValueError:
                            order = 0.0
                    elif attr_local == 'arcrole':
                        arc_role = attr_value
                
                if xlink_from and xlink_to:
                    # Resolve locators to concepts
                    parent_concept = self.locators.get(xlink_from, xlink_from)
                    child_concept = self.locators.get(xlink_to, xlink_to)
                    
                    relation = CalculationRelation(
                        parent_concept=parent_concept,
                        child_concept=child_concept,
                        weight=weight,
                        order=order,
                        arc_role=arc_role
                    )
                    self.calculation_relations.append(relation)
                    arc_count += 1
        
        self.parse_log.append(f"Parsed {arc_count} calculation arcs")
    
    def _parse_presentation_arcs(self, root: ET.Element) -> None:
        """Parse presentationArc elements for hierarchy."""
        arc_count = 0
        
        for elem in root.iter():
            tag_local = elem.tag.split('}')[-1] if '}' in elem.tag else elem.tag
            
            if 'presentationArc' in tag_local or 'PresentationArc' in tag_local:
                xlink_from = None
                xlink_to = None
                order = 0.0
                
                for attr_name, attr_value in elem.attrib.items():
                    attr_local = attr_name.split('}')[-1] if '}' in attr_name else attr_name
                    
                    if attr_local == 'from':
                        xlink_from = attr_value
                    elif attr_local == 'to':
                        xlink_to = attr_value
                    elif attr_local == 'order':
                        try:
                            order = float(attr_value)
                        except ValueError:
                            order = 0.0
                
                if xlink_from and xlink_to:
                    parent = self.locators.get(xlink_from, xlink_from)
                    child = self.locators.get(xlink_to, xlink_to)
                    self.presentation_relations.append((parent, child, order))
                    arc_count += 1
        
        self.parse_log.append(f"Parsed {arc_count} presentation arcs")
    
    def _parse_labels(self, root: ET.Element) -> None:
        """Parse label elements."""
        label_count = 0
        
        for elem in root.iter():
            tag_local = elem.tag.split('}')[-1] if '}' in elem.tag else elem.tag
            
            if tag_local == 'label' and elem.text:
                xlink_label = None
                lang = 'ko'
                
                for attr_name, attr_value in elem.attrib.items():
                    attr_local = attr_name.split('}')[-1] if '}' in attr_name else attr_name
                    
                    if attr_local == 'label':
                        xlink_label = attr_value
                    elif attr_local == 'lang':
                        lang = attr_value
                
                if xlink_label and elem.text.strip():
                    # Resolve to concept
                    concept = self.locators.get(xlink_label, xlink_label)
                    
                    if concept not in self.labels:
                        self.labels[concept] = {}
                    self.labels[concept][lang] = elem.text.strip()
                    label_count += 1
        
        self.parse_log.append(f"Parsed {label_count} labels")
    
    def get_calculation_formula(self, parent_concept: str) -> Tuple[str, List[Tuple[str, float]]]:
        """
        Build calculation formula for a parent concept.
        Returns: (formula_string, [(child, weight), ...])
        """
        children = [
            (rel.child_concept, rel.weight, rel.order)
            for rel in self.calculation_relations
            if rel.parent_concept == parent_concept or 
               self._concepts_match(rel.parent_concept, parent_concept)
        ]
        
        if not children:
            return ("", [])
        
        # Sort by order
        children.sort(key=lambda x: x[2])
        
        # Build formula
        parts = []
        result = []
        
        for child, weight, _ in children:
            child_label = child.split('_')[-1] if '_' in child else child
            if weight >= 0:
                parts.append(f"+ {child_label}")
            else:
                parts.append(f"- {child_label}")
            result.append((child, weight))
        
        parent_label = parent_concept.split('_')[-1] if '_' in parent_concept else parent_concept
        formula = f"{parent_label} = {' '.join(parts)}"
        
        return (formula, result)
    
    def _concepts_match(self, c1: str, c2: str) -> bool:
        """Check if two concept names refer to the same concept."""
        def normalize(c):
            return c.split('#')[-1].split('_')[-1].lower().replace('-', '')
        return normalize(c1) == normalize(c2)


# ============================================================
# MAIN XBRL PARSER
# ============================================================

class XBRLParser:
    """
    Enterprise XBRL/XML parser with full Linkbase support.
    """
    
    UNIT_MULTIPLIERS = {
        'Ï≤úÏõê': 1000,
        'Î∞±ÎßåÏõê': 1000000,
        'ÏñµÏõê': 100000000,
        'thousands': 1000,
        'millions': 1000000,
    }
    
    def __init__(self, taxonomy_type: str = "ifrs"):
        self.taxonomy = TaxonomyLoader(taxonomy_type)
        self.linkbase = LinkbaseParser()
        self.contexts: Dict[str, XBRLContext] = {}
        self.facts: List[XBRLFact] = []
        self.units: Dict[str, str] = {}
        self.raw_xml: str = ""
        self.parse_log: List[str] = []
    
    def parse(self, content: bytes) -> Dict[str, Any]:
        """
        Parse XBRL/XML content.
        Handles both instance documents and linkbase files.
        """
        self.raw_xml = content.decode('utf-8', errors='ignore')
        self.parse_log.append(f"Input size: {len(content)} bytes")
        
        # Register namespaces
        for prefix, uri in NAMESPACES.items():
            ET.register_namespace(prefix, uri)
        
        try:
            root = ET.fromstring(content)
            root_tag = root.tag.split('}')[-1] if '}' in root.tag else root.tag
            self.parse_log.append(f"Root element: {root_tag}")
            
            # Detect document type
            if 'linkbase' in root_tag.lower() or self._is_linkbase_content(root):
                return self._parse_linkbase_document(root)
            else:
                return self._parse_instance_document(root)
                
        except ET.ParseError as e:
            self.parse_log.append(f"Parse error: {e}")
            return self._build_error_result(f"XML ÌååÏã± Ïò§Î•ò: {e}")
    
    def _is_linkbase_content(self, root: ET.Element) -> bool:
        """Check if content is a linkbase by looking for link elements."""
        for elem in root.iter():
            tag = elem.tag.split('}')[-1] if '}' in elem.tag else elem.tag
            if tag in ('calculationLink', 'presentationLink', 'labelLink', 'loc', 'calculationArc'):
                return True
        return False
    
    def _parse_linkbase_document(self, root: ET.Element) -> Dict[str, Any]:
        """Parse a linkbase document (calculation, presentation, label)."""
        self.parse_log.append("Detected linkbase document")
        
        # Check if this is a label linkbase (contains labelLink or label elements)
        is_label_linkbase = False
        for elem in root.iter():
            tag = elem.tag.split('}')[-1] if '}' in elem.tag else elem.tag
            if tag in ('labelLink', 'labelArc') or (tag == 'label' and elem.text):
                is_label_linkbase = True
                break
        
        # Route to dedicated Label Linkbase parser
        if is_label_linkbase:
            self.parse_log.append("Detected label linkbase - using dedicated parser")
            try:
                from .label_linkbase_parser import LabelLinkbaseParser
                label_parser = LabelLinkbaseParser()
                content_bytes = ET.tostring(root, encoding='utf-8')
                return label_parser.parse(content_bytes)
            except ImportError:
                self.parse_log.append("Label linkbase parser not available, using generic")
        
        # Parse linkbase content (calculation/presentation)
        content_bytes = ET.tostring(root, encoding='utf-8')
        self.linkbase.parse(content_bytes)
        
        # Merge parse logs
        self.parse_log.extend(self.linkbase.parse_log)
        
        # Generate structured output from linkbase
        return self._build_linkbase_result()
    
    def _parse_instance_document(self, root: ET.Element) -> Dict[str, Any]:
        """Parse an XBRL instance document."""
        self.parse_log.append("Detected instance document")
        
        # Parse contexts
        for elem in root.iter():
            tag = elem.tag.split('}')[-1] if '}' in elem.tag else elem.tag
            
            if tag == 'context':
                self._parse_context(elem)
            elif tag == 'unit':
                self._parse_unit(elem)
        
        # Parse facts
        for elem in root.iter():
            if elem.text and elem.text.strip():
                self._try_parse_fact(elem)
        
        self.parse_log.append(f"Parsed {len(self.contexts)} contexts, {len(self.facts)} facts")
        
        return self._build_instance_result()
    
    def _parse_context(self, elem: ET.Element) -> None:
        """Parse context element."""
        context_id = elem.get('id', '')
        if not context_id:
            return
        
        context = XBRLContext(id=context_id)
        
        for child in elem.iter():
            tag = child.tag.split('}')[-1] if '}' in child.tag else child.tag
            
            if tag == 'identifier' and child.text:
                context.entity = child.text
            elif tag == 'startDate' and child.text:
                context.start_date = child.text
            elif tag == 'endDate' and child.text:
                context.end_date = child.text
            elif tag == 'instant' and child.text:
                context.instant = child.text
        
        self.contexts[context_id] = context
    
    def _parse_unit(self, elem: ET.Element) -> None:
        """Parse unit element."""
        unit_id = elem.get('id', '')
        if not unit_id:
            return
        
        for child in elem.iter():
            tag = child.tag.split('}')[-1] if '}' in child.tag else child.tag
            if tag == 'measure' and child.text:
                unit_text = child.text.split(':')[-1] if ':' in child.text else child.text
                self.units[unit_id] = unit_text
    
    def _try_parse_fact(self, elem: ET.Element) -> None:
        """Try to parse element as a fact."""
        value = elem.text.strip() if elem.text else ""
        if not value:
            return
        
        context_ref = elem.get('contextRef', '')
        unit_ref = elem.get('unitRef', '')
        
        # Skip non-fact elements
        tag = elem.tag.split('}')[-1] if '}' in elem.tag else elem.tag
        if tag in ('context', 'unit', 'schemaRef', 'linkbaseRef'):
            return
        
        # Build concept identifier
        namespace = elem.tag.split('}')[0].replace('{', '') if '}' in elem.tag else ''
        
        concept = tag
        if namespace:
            if 'ifrs' in namespace.lower():
                concept = f"ifrs-full_{tag}"
            elif 'dart' in namespace.lower():
                concept = f"dart_{tag}"
        
        # Create fact
        decimals_str = elem.get('decimals', '')
        decimals = None
        if decimals_str and decimals_str.lstrip('-').isdigit():
            decimals = int(decimals_str)
        
        fact = XBRLFact(
            concept=concept,
            value=self._standardize_value(value, unit_ref, decimals_str),
            unit=self.units.get(unit_ref, unit_ref),
            context_ref=context_ref,
            decimals=decimals,
            label=self.taxonomy.get_label(concept),
            hierarchy=self.taxonomy.get_hierarchy(concept),
            order=self.taxonomy.get_order(concept),
        )
        
        # Set period
        if context_ref and context_ref in self.contexts:
            ctx = self.contexts[context_ref]
            if ctx.instant:
                fact.period = ctx.instant[:4]
            elif ctx.end_date:
                fact.period = ctx.end_date[:4]
        
        self.facts.append(fact)
    
    def _standardize_value(self, value: str, unit_ref: str, decimals: str) -> str:
        """
        Self-Healing ÏàòÏπò ÌëúÏ§ÄÌôî (v3)
        
        üî¥ ÌïµÏã¨ Î°úÏßÅ:
        1. ÏõêÎ≥∏Í∞íÏù¥ Ïù¥ÎØ∏ ÌÅ¨Î©¥(‚â•10^6) Ïä§ÏºÄÏùºÎßÅ Í±¥ÎÑàÎõ∞Í∏∞
        2. Ïä§ÏºÄÏùºÎßÅ ÌõÑ Î≤îÏúÑ Ï¥àÍ≥º Ïãú ÏûêÎèô Ïó≠ÏÇ∞(Reverse Scaling)
        """
        clean = value.replace(',', '').replace(' ', '')
        
        # Filter URLs, XSD refs
        if 'http' in clean.lower() or 'xsd' in clean.lower():
            return value
        
        try:
            numeric = float(clean)
            original = numeric
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # STEP 1: Self-Healing - ÏõêÎ≥∏Í∞íÏù¥ ÌÅ¨Î©¥ Ïä§ÏºÄÏùºÎßÅ Í±¥ÎÑàÎõ∞Í∏∞
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            RAW_VALUE_LARGE_THRESHOLD = 1e6  # 100Îßå Ïù¥ÏÉÅÏùÄ Ïù¥ÎØ∏ Ïã§Ï†úÍ∞í
            skip_scaling = abs(numeric) >= RAW_VALUE_LARGE_THRESHOLD
            
            if skip_scaling and decimals and decimals.lstrip('-').isdigit():
                dec = int(decimals)
                if dec < 0:
                    # ÏõêÎ≥∏Ïù¥ ÌÅ¨Í≥† decimalsÎèÑ ÏùåÏàò ‚Üí Ïä§ÏºÄÏùºÎßÅ Í±¥ÎÑàÎõ∞Í∏∞
                    return f"{int(numeric):,}"
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # STEP 2: Ï°∞Í±¥Î∂Ä Ïä§ÏºÄÏùºÎßÅ (ÏõêÎ≥∏Ïù¥ ÏûëÏùÑ ÎïåÎßå)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            scale_applied = False
            if not skip_scaling and decimals and decimals.lstrip('-').isdigit():
                dec = int(decimals)
                if dec < 0:
                    numeric *= (10 ** abs(dec))
                    scale_applied = True
            
            if not scale_applied:
                unit_text = self.units.get(unit_ref, '').lower()
                for pattern, mult in self.UNIT_MULTIPLIERS.items():
                    if pattern in unit_text:
                        numeric *= mult
                        break
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # STEP 3: Self-Healing Ïó≠ÏÇ∞ (Overflow ÏûêÎèô Î≥¥Ï†ï)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            MAX_REASONABLE = 1e13  # 10Ï°∞ Îã¨Îü¨ (Apple Ï¥ùÏûêÏÇ∞Ïùò 10Î∞∞)
            
            if abs(numeric) > MAX_REASONABLE:
                # ÏûêÎèô Ïó≠ÏÇ∞ ÏãúÎèÑ
                for factor in [1e12, 1e9, 1e6]:
                    corrected = numeric / factor
                    if abs(corrected) <= MAX_REASONABLE and abs(corrected) >= 1:
                        numeric = corrected
                        break
                else:
                    # Ïó¨Ï†ÑÌûà Î≤îÏúÑ Ï¥àÍ≥ºÎ©¥ ÏõêÎ≥∏ ÏÇ¨Ïö©
                    numeric = original
            
            return f"{int(numeric):,}"
        except ValueError:
            return value
    
    def _build_linkbase_result(self) -> Dict[str, Any]:
        """Build result from linkbase parsing."""
        tables = []
        
        # Build calculation relationships table
        if self.linkbase.calculation_relations:
            calc_rows = []
            for rel in sorted(self.linkbase.calculation_relations, key=lambda r: r.order):
                parent_label = self.taxonomy.get_label(rel.parent_concept)
                child_label = self.taxonomy.get_label(rel.child_concept)
                weight_str = "+" if rel.weight >= 0 else "-"
                
                calc_rows.append([
                    parent_label,
                    f"{weight_str} {child_label}",
                    str(rel.order)
                ])
            
            tables.append({
                "name": "Í≥ÑÏÇ∞Í¥ÄÍ≥Ñ (Calculation Linkbase)",
                "headers": ["ÏÉÅÏúÑ Ìï≠Î™©", "ÌïòÏúÑ Ìï≠Î™© (Í∞ÄÏ§ëÏπò)", "ÏàúÏÑú"],
                "rows": calc_rows
            })
        
        # Build presentation hierarchy table
        if self.linkbase.presentation_relations:
            hier_rows = []
            for parent, child, order in sorted(self.linkbase.presentation_relations, key=lambda x: x[2]):
                parent_label = self.taxonomy.get_label(parent)
                child_label = self.taxonomy.get_label(child)
                hier_rows.append([parent_label, child_label, str(order)])
            
            tables.append({
                "name": "ÌëúÏãúÍ≥ÑÏ∏µ (Presentation Linkbase)",
                "headers": ["ÏÉÅÏúÑ Ìï≠Î™©", "ÌïòÏúÑ Ìï≠Î™©", "ÏàúÏÑú"],
                "rows": hier_rows
            })
        
        # Build formulas
        formulas = []
        seen_parents = set()
        for rel in self.linkbase.calculation_relations:
            if rel.parent_concept not in seen_parents:
                formula, components = self.linkbase.get_calculation_formula(rel.parent_concept)
                if formula:
                    formulas.append({
                        "parent": rel.parent_concept,
                        "label": self.taxonomy.get_label(rel.parent_concept),
                        "formula": formula,
                        "components": [(c, w) for c, w in components]
                    })
                    seen_parents.add(rel.parent_concept)
        
        return {
            "title": "XBRL Linkbase Î∂ÑÏÑù",
            "summary": self._generate_linkbase_summary(),
            "tables": tables,
            "formulas": formulas,
            "key_metrics": {
                "locator_count": len(self.linkbase.locators),
                "calculation_relations": len(self.linkbase.calculation_relations),
                "presentation_relations": len(self.linkbase.presentation_relations),
            },
            "facts": [],  # Linkbase has no facts
            "parse_log": self.parse_log + self.linkbase.parse_log,
            "metadata": {
                "file_type": "xbrl-linkbase",
                "taxonomy": self.taxonomy.taxonomy_type,
                "processed_by": "xbrl-parser-v2"
            }
        }
    
    def _build_instance_result(self) -> Dict[str, Any]:
        """Build result from instance document parsing."""
        sorted_facts = sorted(self.facts, key=lambda f: f.order)
        
        # Validate: check for numeric data
        numeric_facts = [f for f in sorted_facts if self._is_numeric_value(f.value)]
        if len(numeric_facts) == 0:
            self.parse_log.append("‚ö†Ô∏è WARNING: No numeric data extracted")
            return self._build_empty_data_error(
                "ÏàòÏπò Îç∞Ïù¥ÌÑ∞Í∞Ä Ï∂îÏ∂úÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. ÌååÏùº ÌòïÏãùÏùÑ ÌôïÏù∏ÌïòÏÑ∏Ïöî."
            )
        
        self.parse_log.append(f"‚úÖ Extracted {len(numeric_facts)} numeric facts")
        
        # Group by hierarchy
        tables_dict: Dict[str, List[Dict]] = defaultdict(list)
        for fact in sorted_facts:
            root = fact.hierarchy.split(' > ')[0] if fact.hierarchy else "Í∏∞ÌÉÄ"
            tables_dict[root].append({
                "concept": fact.concept,
                "label": fact.label,
                "value": fact.value,
                "unit": fact.unit,
                "period": fact.period,
            })
        
        tables = [
            {
                "name": name,
                "headers": ["Ìï≠Î™©", "Í∏àÏï°", "Í∏∞Í∞Ñ"],
                "rows": [[item["label"], item["value"], item["period"]] for item in items]
            }
            for name, items in tables_dict.items()
        ]
        
        return {
            "title": "XBRL Ïû¨Î¨¥Îç∞Ïù¥ÌÑ∞",
            "summary": self._generate_instance_summary(),
            "tables": tables,
            "key_metrics": self._extract_key_metrics(),
            "facts": [
                {
                    "concept": f.concept,
                    "label": f.label,
                    "value": f.value,
                    "unit": f.unit,
                    "period": f.period,
                    "hierarchy": f.hierarchy,
                }
                for f in sorted_facts
            ],
            "parse_log": self.parse_log,
            "metadata": {
                "file_type": "xbrl-instance",
                "taxonomy": self.taxonomy.taxonomy_type,
                "fact_count": len(self.facts),
                "context_count": len(self.contexts),
                "processed_by": "xbrl-parser-v2"
            }
        }
    
    def _build_error_result(self, error_msg: str) -> Dict[str, Any]:
        """Build error result with structural info."""
        # Try to extract any structural information
        structural_info = []
        try:
            for line in self.raw_xml[:5000].split('\n'):
                if '<' in line and '>' in line:
                    structural_info.append(line.strip()[:100])
        except:
            pass
        
        return {
            "title": "XBRL ÌååÏã± Ïò§Î•ò",
            "summary": error_msg,
            "tables": [],
            "key_metrics": {},
            "facts": [],
            "parse_log": self.parse_log,
            "structural_info": structural_info[:20],
            "metadata": {
                "file_type": "xbrl",
                "error": error_msg,
                "processed_by": "xbrl-parser-v2"
            }
        }
    
    def _generate_linkbase_summary(self) -> str:
        """Generate summary for linkbase."""
        calc_count = len(self.linkbase.calculation_relations)
        pres_count = len(self.linkbase.presentation_relations)
        loc_count = len(self.linkbase.locators)
        
        if calc_count == 0 and pres_count == 0 and loc_count == 0:
            return "Linkbase ÌååÏã± Ïã§Ìå®: Îç∞Ïù¥ÌÑ∞Î•º Ï∂îÏ∂úÌïòÏßÄ Î™ªÌñàÏäµÎãàÎã§. " + "; ".join(self.parse_log[-5:])
        
        return (f"XBRL LinkbaseÏóêÏÑú {loc_count}Í∞ú Í∞úÎÖê, "
                f"{calc_count}Í∞ú Í≥ÑÏÇ∞Í¥ÄÍ≥Ñ, {pres_count}Í∞ú ÌëúÏãúÍ¥ÄÍ≥ÑÎ•º Ï∂îÏ∂úÌñàÏäµÎãàÎã§.")
    
    def _generate_instance_summary(self) -> str:
        """Generate summary for instance document."""
        if not self.facts:
            return "Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú Ïã§Ìå®. " + "; ".join(self.parse_log[-5:])
        
        periods = set(f.period for f in self.facts if f.period)
        hierarchies = set(f.hierarchy.split(' > ')[0] for f in self.facts if f.hierarchy)
        
        return (f"XBRL Î¨∏ÏÑúÏóêÏÑú {len(self.facts)}Í∞ú Ìï≠Î™©ÏùÑ Ï∂îÏ∂ú. "
                f"Í∏∞Í∞Ñ: {', '.join(sorted(periods))}. Ïû¨Î¨¥Ï†úÌëú: {', '.join(hierarchies)}.")
    
    def _is_numeric_value(self, value: str) -> bool:
        """Check if a value is numeric."""
        if not value:
            return False
        clean = str(value).replace(',', '').replace(' ', '').replace('-', '').replace('.', '')
        return clean.isdigit()
    
    def _build_empty_data_error(self, error_msg: str) -> Dict[str, Any]:
        """Build error result for empty numeric data case."""
        return {
            "title": "XBRL ÌååÏã± Ïã§Ìå® - ÏàòÏπò Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå",
            "summary": error_msg,
            "tables": [],
            "key_metrics": {},
            "facts": [],
            "parse_log": self.parse_log,
            "metadata": {
                "file_type": "xbrl-instance",
                "taxonomy": self.taxonomy.taxonomy_type,
                "fact_count": 0,
                "error": error_msg,
                "processed_by": "xbrl-parser-v2"
            }
        }
    
    def _extract_key_metrics(self) -> Dict[str, str]:
        """Extract key financial metrics."""
        metrics = {}
        key_concepts = [
            ("Revenue", "Îß§Ï∂úÏï°"),
            ("GrossProfit", "Îß§Ï∂úÏ¥ùÏù¥Ïùµ"),
            ("OperatingProfit", "ÏòÅÏóÖÏù¥Ïùµ"),
            ("ProfitLoss", "ÎãπÍ∏∞ÏàúÏù¥Ïùµ"),
            ("Assets", "Ï¥ùÏûêÏÇ∞"),
            ("Liabilities", "Ï¥ùÎ∂ÄÏ±Ñ"),
            ("Equity", "Ï¥ùÏûêÎ≥∏"),
        ]
        
        for concept_suffix, label in key_concepts:
            for fact in self.facts:
                if concept_suffix.lower() in fact.concept.lower():
                    key = f"{label}_{fact.period}" if fact.period else label
                    metrics[key] = f"{fact.value} {fact.unit or 'Ïõê'}"
                    break
        
        return metrics
    
    def get_raw_context(self, concept: str) -> str:
        """Get raw XML context for a concept."""
        pattern = rf'<[^>]*{concept}[^>]*>.*?</[^>]*>'
        match = re.search(pattern, self.raw_xml, re.IGNORECASE | re.DOTALL)
        return match.group(0) if match else ""


# Singleton
xbrl_parser = XBRLParser()
