"""
FinDistill XBRL Semantic Engine v17.0 (Asura: AI Economist + Dynamic Simulation)
"""

import json
import logging
import os
import re
import traceback
import xml.etree.ElementTree as ET
from collections import Counter
from dataclasses import dataclass, field
from datetime import datetime
from decimal import Decimal, InvalidOperation, ROUND_HALF_UP
from typing import Any, Dict, List, Optional, Tuple

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

from .xbrl_enhancements import LabelManager, DimensionManager

@dataclass
class SemanticFact:
    concept: str
    label: str
    value: Decimal
    raw_value: str
    unit: str
    period: str
    context_ref: str
    decimals: Optional[int]
    is_consolidated: bool = True
    dimensions: Optional[Dict[str, str]] = None
    confidence_score: float = 1.0  # v16.0 Spoke B
    tags: List[str] = field(default_factory=list) # v16.0 Spoke B (e.g. [Projected], [Healed])
    geo_sentiment: float = 0.0 # v17.0 Spoke B (Geo-Quant)

@dataclass
class XBRLIntelligenceResult:
    success: bool
    company_name: str
    fiscal_year: str
    facts: List[SemanticFact]
    reasoning_qa: List[Dict[str, str]]
    financial_report_md: str
    jsonl_data: List[str]
    key_metrics: Dict[str, Any]
    parse_summary: str
    errors: List[str]

class UnitManager:
    @staticmethod
    def detect_unit_type(unit_ref: str, concept_name: str) -> str:
        u = unit_ref.lower()
        c = concept_name.lower()
        if 'share' in u or 'share' in c: return 'shares'
        if 'pure' in u or 'ratio' in c or 'rate' in c or 'percentage' in c or 'margin' in c: return 'ratio'
        return 'currency'

    @staticmethod
    def format_value(value: Decimal, unit_type: str) -> str:
        if unit_type == 'currency':
            # [Prompt Patch] Hard-fix Units: Force $B, no $T
            return f"${value:,.3f}B"
        elif unit_type == 'shares':
            return f"{value:,.0f} Shares"
        elif unit_type == 'ratio':
            if abs(value) <= 10: return f"{value * 100:.2f}%"
            else: return f"{value:.2f}"
        return f"{value:,.2f}"

class ScaleProcessor:
    # v17.0 Logic 3: Error Pattern Memory
    error_pattern_memory = []

    @classmethod
    def normalize_to_billion(cls, value: Decimal) -> Decimal:
        return (value / Decimal("1000000000")).quantize(Decimal("0.000001"), rounding=ROUND_HALF_UP)

    @classmethod
    def apply_self_healing(cls, raw_val: str, decimals: Optional[int] = None, unit_type: str = 'currency') -> Tuple[Decimal, str, float]:
        """
        Returns: (Value, Tag, Confidence_Score)
        """
        try:
            clean_val = re.sub(r'[^-0-9.]', '', raw_val)
            if not clean_val: return Decimal("0"), "zero_fallback", 0.1
            val = Decimal(clean_val)
            
            if unit_type == 'currency':
                normalized = cls.normalize_to_billion(val)
                # [Phase 3] Global Unit Lock & Scale Normalization
                
                # 1. Trillion ($T) Error Protection (Boeing Case: 77.7T -> 77.7B)
                if abs(normalized) > 1000:
                    while abs(normalized) > 1000:
                        normalized /= 1000
                    
                    # v17.0 Logic 3: Log Pattern
                    cls.error_pattern_memory.append({"type": "outlier_trillion", "raw": str(val), "healed": str(normalized)})
                    return normalized, "healed_outlier_trillion", 0.7 
                    
                # 2. Micro-Scale Protection
                if abs(normalized) > 0 and abs(normalized) < Decimal("0.0001"):
                     normalized *= 1000
                     cls.error_pattern_memory.append({"type": "micro_scale", "raw": str(val), "healed": str(normalized)})
                     return normalized, "healed_micro_scale", 0.7

                return normalized, "healed_billion", 1.0 
            else:
                return val, "raw_pass", 1.0
        except:
            return Decimal("0"), "error_fallback", 0.0

class ExpertCoTGenerator:
    """
    Unified English Chain-of-Thought Generator (v17.0 Enhanced).
    """

    @staticmethod
    def _get_intelligent_context(metric_name: str) -> Dict[str, str]:
        return {
            "definition": f"The {metric_name} is a key financial metric.",
            "significance": "It indicates operational performance and financial health."
        }

    @staticmethod
    def detect_industry(company_name: str) -> str:
        name = company_name.lower()
        if any(x in name for x in ['pfizer', 'lilly', 'merck', 'pharma', 'biotech', 'moderna']): return "Pharmaceuticals"
        elif any(x in name for x in ['starbucks', 'sbux', 'mcdonald', 'chipotle', 'food', 'beverage', 'coffee', 'coke', 'pepsi']): return "Consumer (Food & Beverage)"
        elif any(x in name for x in ['ford', 'tesla', 'gm', 'general motors', 'toyota', 'honda', 'auto', 'motor', 'f_']): return "Automotive"
        elif any(x in name for x in ['airbnb', 'abnb', 'uber', 'lyft', 'booking', 'expedia', 'platform', 'meta', 'netflix']): return "IT Platform"
        elif any(x in name for x in ['bank', 'capital', 'financial', 'insurance', 'jpm', 'goldman']): return "Financial Services"
        elif any(x in name for x in ['tech', 'software', 'microsoft', 'google', 'apple', 'nvidia', 'amd', 'intel', 'cisco', 'csco']): return "Technology"
        elif any(x in name for x in ['boeing', 'ba', 'airbus', 'lockheed', 'defense', 'aerospace']): return "Aerospace & Defense"
        elif any(x in name for x in ['ge', 'general electric', 'industrial']): return "Industrial"
        return "General Corporate"

    @staticmethod
    def _calculate_sensitivity_beta(industry: str) -> float:
        # v17.0 Logic 2: Sensitivity Beta (Mock Regression Logic)
        if industry in ["Automotive", "Industrial", "Aerospace & Defense"]: return 2.4 
        elif industry in ["Technology", "IT Platform"]: return 0.8 
        elif industry in ["Financial Services"]: return -1.5 
        return 1.2 

    @staticmethod
    def generate(
        metric_name: str,
        company_name: str,
        industry: str,
        cy_val: Decimal,
        py_val: Optional[Decimal] = None,
        definition_text: Optional[str] = None,
        py_label: str = "PY",
        unit_type: str = "currency",
        fiscal_year: Optional[str] = None,
        cy_date: Optional[str] = None,
        py_date: Optional[str] = None,
        is_projected: bool = False
    ) -> str:
        
        # 1. Context
        if not definition_text:
            ctx = ExpertCoTGenerator._get_intelligent_context(metric_name)
            definition_text = f"**Definition**: {ctx['definition']}\n**Industrial Significance**: {ctx['significance']}"

        # 2. Synthesis
        cy_display = f"CY ({cy_date})" if cy_date else f"CY ({fiscal_year})"
        cy_fmt = UnitManager.format_value(cy_val, unit_type)
        
        py_str = "N/A"
        growth = 0.0
        has_py = False
        
        # v17.0 Logic 2: Quantitative Sensitivity Beta
        macro_note = ""
        if "interest" in metric_name.lower() or "debt" in metric_name.lower():
            beta = ExpertCoTGenerator._calculate_sensitivity_beta(industry)
            impact = "negative" if beta > 0 else "positive"
            macro_note = f"\n\n[Macro-Micro Link v17.0]\nInterest Rate Sensitivity Beta (Î²_ir): {beta}. A 100bp rate hike is projected to have a {abs(beta)}% {impact} impact on this metric, reflecting the sector's capital structure."

        if py_val is not None:
            has_py = True
            py_display = f"{py_label} ({py_date})" if py_date else py_label
            py_fmt = UnitManager.format_value(py_val, unit_type)
            if is_projected:
                py_fmt += " [Projected]"
            py_str = f"{py_display}: {py_fmt}"
            
            if py_val != 0:
                growth = float((cy_val - py_val) / abs(py_val) * 100)
                formula = f"$$Growth = \\frac{{{cy_val:.3f} - {py_val:.3f}}}{{|{py_val:.3f}|}} \\times 100\\% = {growth:+.2f}\\%$$"
            else:
                formula = "$$Growth = \\text{N/A (Div/0)}$$"
        else:
             formula = "$$Growth = \\text{N/A (Historical comparison unavailable)}$$"

        synthesis = f"{cy_display}: {cy_fmt}, {py_str}."

        # 4. Insight
        cleaned_metric = metric_name.replace('_', ' ')
        insight = f"Based on {industry} sector analysis, {company_name} reports {cleaned_metric} of {cy_fmt}. "
        
        if industry == "Pharmaceuticals":
            insight += "This performance correlates with R&D pipeline maturation and key drug portfolio milestones. "
        elif "Consumer" in industry:
            insight += "This reflects same-store sales growth (SSSG) and customer traffic dynamics. "
        elif industry == "Automotive":
            insight += "This highlights inventory turnover rates and global production efficiency. "
        elif industry == "IT Platform":
            insight += "This is closely tied to Monthly Active Users (MAU) and platform engagement metrics. "
        elif industry == "Aerospace & Defense":
             insight += "This reflects order backlog delivery and defense contract fulfillment. "
        elif industry == "Technology":
             insight += "This reflects cloud infrastructure scaling and software subscription renewals. "
        elif industry == "Industrial":
             insight += "This reflects supply chain optimization and backlog execution. "
        else:
             insight += "This metric reflects core operational efficiency and market position stability. "
            
        if has_py:
            trend = "growth" if growth > 0 else "decline"
            insight += f"The {growth:+.1f}% {trend} emphasizes market adaptability."
            if is_projected:
                insight += " (Note: Prior Year data was imputed using Dynamic Industry Proxy)."
            
        return f"[Intelligent Context]\n{definition_text}\n\n[Synthesis]\n{synthesis}\n\n[Symbolic Reasoning]\n{formula}{macro_note}\n\n[Professional Insight]\n{insight}"

class XBRLSemanticEngine:
    """
    Primary engine for distillation financial XML into JSONL.
    V17.0 (Asura): Enhanced with Dynamic Industry Proxy, Sensitivity Beta, and Scenario Simulation.
    """

    def __init__(self, company_name: str = "Target Corp", fiscal_year: str = "2024", file_path: str = "unknown_file"):
        self.company_name = company_name
        self.fiscal_year = fiscal_year
        self.file_path = file_path
        self.facts: List[SemanticFact] = []
        self.reasoning_qa: List[Dict[str, str]] = []
        self.errors: List[str] = []
        self.period_date_map: Dict[str, str] = {}
        
        # Linkbase Storage
        self.presentation_tree = {} # .pre
        self.calculation_rules = [] # .cal
        self.label_map = {}         # .lab
        self.definition_map = {}    # .def
        self.concept_types = {}     # .xsd
        
        self.base_dir = os.path.dirname(file_path) if file_path else ""
        self.filename_base = os.path.splitext(os.path.basename(file_path))[0] if file_path else ""

    def load_linkbases(self):
        """Step 0: Load all available 5 linkbases (.xsd, .cal, .def, .lab, .pre)"""
        if not self.base_dir: 
            # Infer base dir from file_path if available
            if self.file_path:
                self.base_dir = os.path.dirname(os.path.abspath(self.file_path))
                self.filename_base = os.path.splitext(os.path.basename(self.file_path))[0]
            else:
                return

        def find_linkbase(suffix_list):
            try:
                if not os.path.exists(self.base_dir): return None
                for f in os.listdir(self.base_dir):
                    if f.startswith(self.filename_base) and any(f.endswith(s) for s in suffix_list):
                        return os.path.join(self.base_dir, f)
            except: pass
            return None

        # 1. Schema (.xsd)
        xsd_path = find_linkbase(['.xsd'])
        if xsd_path: self._parse_xsd(xsd_path)

        # 2. Calculation (.cal)
        cal_path = find_linkbase(['_cal.xml', '.cal'])
        if cal_path: self._parse_cal(cal_path)
        
        # 3. Presentation (.pre)
        pre_path = find_linkbase(['_pre.xml', '.pre'])
        if pre_path: self._parse_pre(pre_path)

        # 4. Label (.lab)
        lab_path = find_linkbase(['_lab-en.xml', '_lab.xml', '.lab'])
        if lab_path: self._parse_lab(lab_path)

        # 5. Definition (.def)
        def_path = find_linkbase(['_def.xml', '.def'])
        if def_path: self._parse_def(def_path)

    def _parse_xsd(self, path):
        try:
            tree = ET.fromstring(open(path, 'rb').read())
            for elem in tree.iter():
                if 'name' in elem.attrib and 'type' in elem.attrib:
                    name = elem.attrib['name']
                    dtype = elem.attrib['type']
                    self.concept_types[name] = dtype
            logger.info(f"Loaded {len(self.concept_types)} types from XSD.")
        except Exception as e: logger.warning(f"XSD Load Failed: {e}")

    def _parse_cal(self, path):
        try:
            tree = ET.fromstring(open(path, 'rb').read())
            locs = {}
            for loc in tree.iter():
                if loc.tag.endswith('loc'):
                    label = loc.attrib.get('{http://www.w3.org/1999/xlink}label')
                    href = loc.attrib.get('{http://www.w3.org/1999/xlink}href')
                    if label and href:
                        concept = href.split('#')[-1]
                        locs[label] = concept

            for arc in tree.iter():
                if arc.tag.endswith('calculationArc'):
                    weight = float(arc.attrib.get('weight', 0))
                    from_lbl = arc.attrib.get('{http://www.w3.org/1999/xlink}from', '')
                    to_lbl = arc.attrib.get('{http://www.w3.org/1999/xlink}to', '')
                    
                    if from_lbl in locs and to_lbl in locs:
                        parent = locs[from_lbl]
                        child = locs[to_lbl]
                        self.calculation_rules.append((parent, child, weight))
                        
            logger.info(f"Loaded {len(self.calculation_rules)} Calculation Rules.")
        except Exception as e: logger.warning(f"CAL Load Failed: {e}")

    def _parse_pre(self, path):
        try:
            tree = ET.fromstring(open(path, 'rb').read())
            logger.info("Loaded Presentation Hierarchy (Placeholder).")
        except Exception as e: logger.warning(f"PRE Load Failed: {e}")

    def _parse_lab(self, path):
         try:
             tree = ET.fromstring(open(path, 'rb').read())
             locs = {}
             for loc in tree.iter():
                 if loc.tag.endswith('loc'):
                     label = loc.attrib.get('{http://www.w3.org/1999/xlink}label')
                     href = loc.attrib.get('{http://www.w3.org/1999/xlink}href')
                     if label and href:
                         concept = href.split('#')[-1]
                         locs[label] = concept

             label_res = {}
             for res in tree.iter():
                 if res.tag.endswith('label'):
                     label_id = res.attrib.get('{http://www.w3.org/1999/xlink}label')
                     role = res.attrib.get('{http://www.w3.org/1999/xlink}role')
                     text = res.text
                     if label_id and text:
                         if role and 'documentation' not in role: 
                             label_res[label_id] = text

             for arc in tree.iter():
                 if arc.tag.endswith('labelArc'):
                     from_lbl = arc.attrib.get('{http://www.w3.org/1999/xlink}from')
                     to_lbl = arc.attrib.get('{http://www.w3.org/1999/xlink}to')
                     
                     if from_lbl in locs and to_lbl in label_res:
                         concept = locs[from_lbl]
                         text = label_res[to_lbl]
                         self.label_map[concept] = text

             logger.info(f"Loaded {len(self.label_map)} Labels.")
         except Exception as e: logger.warning(f"LAB Load Failed: {e}")

    def _parse_def(self, path):
         try:
             tree = ET.fromstring(open(path, 'rb').read())
             logger.info("Loaded Definitions (Placeholder).")
         except: pass

    def apply_arithmetic_self_healing(self):
        """Step 2: Arithmetic Self-Healing using CAL rules."""
        if not self.facts: return

        fact_map = {}
        for f in self.facts:
            if f.context_ref not in fact_map: fact_map[f.context_ref] = {}
            fact_map[f.context_ref][f.concept] = f

        rules_by_parent = {}
        for p, c, w in self.calculation_rules:
            if p not in rules_by_parent: rules_by_parent[p] = []
            rules_by_parent[p].append((c, w))

        healed_count = 0
        
        for ctx_id, concepts in fact_map.items():
            for parent, children in rules_by_parent.items():
                if parent not in concepts: continue
                
                calculated_sum = Decimal(0)
                children_present = False
                
                for child, weight in children:
                    if child in concepts:
                        calculated_sum += concepts[child].value * Decimal(weight)
                        children_present = True
                
                if not children_present: continue

                parent_val = concepts[parent].value
                
                if abs(calculated_sum - parent_val) > Decimal("1.0"):
                    logger.info(f"[Arithmetic Check] Discrepancy for {parent} in {ctx_id}: Calculated {calculated_sum} != Reported {parent_val}")
                    
                    if abs(calculated_sum - (parent_val * 1000)) < Decimal("10.0"):
                        logger.warning(f"[Self-healing]: Scaled {parent} (x1000) to match children sum.")
                        concepts[parent].value *= 1000
                        concepts[parent].raw_value += " [Healed: x1000]"
                        concepts[parent].confidence_score = 0.7 
                        concepts[parent].tags.append("[Healed]")
                        healed_count += 1
                        continue

                    if abs((calculated_sum / 1000) - parent_val) < Decimal("10.0"):
                         logger.warning(f"[Self-healing]: Scaled Children (div 1000) to match parent.")
                         pass

        if healed_count > 0:
            logger.info(f"Step 2 Complete: Applied {healed_count} arithmetic fixes.")

    def _get_dynamic_industry_growth(self, industry: str) -> Decimal:
        """
        v17.0 Logic 1: Dynamic Industry Proxy
        In real system, this queries Supabase for real-time peer average.
        Here we implement a mock logic based on sector trends.
        """
        growth_rates = {
            "Technology": Decimal("1.12"), # 12% Growth
            "IT Platform": Decimal("1.15"),
            "Automotive": Decimal("1.03"),
            "Pharmaceuticals": Decimal("1.05"),
            "Financial Services": Decimal("1.04"),
            "Industrial": Decimal("1.02"),
            "Consumer (Food & Beverage)": Decimal("1.04")
        }
        return growth_rates.get(industry, Decimal("1.05")) # Default 5%

    def _generate_reasoning_qa(self, facts: List[SemanticFact]) -> List[Dict[str, str]]:
        self.reasoning_qa = []
        concept_groups = {}
        for f in facts:
            if f.concept not in concept_groups: concept_groups[f.concept] = {}
            concept_groups[f.concept][f.period] = f
            
        for concept, periods in concept_groups.items():
            cy_f = periods.get("CY")
            if not cy_f: continue
            
            py_keys = [k for k in periods.keys() if k.startswith("PY")]
            
            # v17.0 Logic 1: Dynamic Industry Proxy Imputation
            is_projected = False
            target_pys = py_keys if py_keys else [None]
            
            if not py_keys:
                if any(x in concept.lower() for x in ['revenue', 'income', 'profit', 'sales']):
                    industry = ExpertCoTGenerator.detect_industry(self.company_name)
                    growth_factor = self._get_dynamic_industry_growth(industry)
                    
                    # Reverse engineer PY from CY based on growth factor
                    imputed_py_val = cy_f.value / growth_factor
                    
                    target_pys = ["PY_Imputed"]
                    is_projected = True
                    periods["PY_Imputed"] = SemanticFact(
                        concept, f"{cy_f.label} (Projected)", imputed_py_val, "0", cy_f.unit, "PY_Imputed", "imputed", 0, confidence_score=0.3, tags=["[Projected]", "[DynamicProxy]"]
                    )

            for py_key in target_pys:
                py_f = periods.get(py_key) if py_key else None
                p_val = py_f.value if py_f else None
                
                if p_val is not None and cy_f.value == p_val and cy_f.period == (py_f.period if py_f else ""):
                    continue

                industry = ExpertCoTGenerator.detect_industry(self.company_name)
                
                response = ExpertCoTGenerator.generate(
                    metric_name=concept,
                    company_name=self.company_name,
                    industry=industry,
                    cy_val=cy_f.value,
                    py_val=p_val,
                    unit_type=cy_f.unit,
                    fiscal_year=self.fiscal_year,
                    cy_date=self.period_date_map.get("CY"),
                    py_date=self.period_date_map.get(py_key) if py_key else None,
                    is_projected=is_projected
                )
                
                if response:
                    q_text = f"Analyze the YoY trend of {self.company_name} - {concept} ({cy_f.period} vs {py_key or 'N/A'})."
                    if is_projected:
                        q_text += " [Data Imputed]"
                        
                    self.reasoning_qa.append({
                        "question": q_text,
                        "response": response,
                        "type": "financial_analysis"
                    })
                    
                    # v17.0 Spoke A: Scenario Spoke (What-if Simulation)
                    # Trigger: If Revenue or Net Income, generate a simple oil shock scenario for Auto/Ind
                    if industry in ["Automotive", "Industrial", "Aerospace & Defense"] and "netincome" in concept.lower():
                        shock_impact = cy_f.value * Decimal("0.85") # -15% impact from Oil Shock
                        scenario_text = f"[Scenario: Oil Price +20%]\nProjected Net Income would decrease to {UnitManager.format_value(shock_impact, cy_f.unit)} due to rising input costs."
                        self.reasoning_qa.append({
                            "question": f"Simulation: Impact of 20% Oil Price Hike on {self.company_name} {concept}?",
                            "response": scenario_text,
                            "type": "scenario_simulation"
                        })

        return self.reasoning_qa

    def _generate_jsonl(self, reasoning_qa: List[Dict[str, str]]) -> List[str]:
        jsonl_lines = []
        korean_pattern = re.compile(r'[\uAC00-\uD7A3]')
        for qa in reasoning_qa:
            entry = {
                "instruction": f"Analyze the YoY trend of {self.company_name} - {qa.get('type', 'financial')}.",
                "input": f"{self.company_name} {self.fiscal_year} Financial Data",
                "output": qa["response"],
                "metadata": {"company": self.company_name, "year": self.fiscal_year}
            }
            line = json.dumps(entry, ensure_ascii=False)
            if korean_pattern.search(line): raise RuntimeError("KOREAN_DETECTED")
            jsonl_lines.append(line)
        return jsonl_lines

    def process_joint(self, instance_content: bytes, label_content: Optional[bytes] = None) -> XBRLIntelligenceResult:
        try:
            self.load_linkbases()
            
            label_mgr = LabelManager(label_content)
            
            tree = ET.fromstring(instance_content)
            for elem in tree.iter():
                if '}' in elem.tag: elem.tag = elem.tag.split('}', 1)[1]

            contexts, context_dims = self._parse_contexts_and_dims(tree)
            self._extract_metadata(tree)
            
            facts = self._extract_facts(tree, contexts, context_dims, label_mgr)
            self.facts = facts
            
            self.apply_arithmetic_self_healing()
            
            qa_pairs = self._generate_reasoning_qa(self.facts)
            jsonl_data = self._generate_jsonl(qa_pairs)

            summary = "Analysis complete."
            for qa in qa_pairs:
                if qa.get("type") == "summary": summary = qa["response"]; break

            return XBRLIntelligenceResult(True, self.company_name, self.fiscal_year, self.facts, qa_pairs, "# Report", jsonl_data, {}, summary, self.errors)
        except Exception as e:
            logger.error(f"Processing failed: {e}")
            import traceback
            traceback.print_exc()
            return XBRLIntelligenceResult(False, self.company_name, self.fiscal_year, [], [], "", [], {}, str(e), [str(e)])

    def _extract_metadata(self, tree: Any):
        for tag in ['EntityRegistrantName', 'EntityCentralIndexKey']:
            elem = tree.find(f".//{tag}")
            if elem is not None and elem.text: self.company_name = elem.text; break
        for tag in ['DocumentFiscalYearFocus', 'DocumentPeriodEndDate']:
            elem = tree.find(f".//{tag}")
            if elem is not None and elem.text: 
                text = elem.text.strip()
                if len(text) >= 4: self.fiscal_year = text[:4]; break

    def _parse_contexts_and_dims(self, tree: Any) -> Tuple[Dict[str, str], Dict[str, Dict[str, str]]]:
        context_map = {}
        context_dims = {}
        date_counts = Counter()
        ctx_date_map = {}

        for ctx in tree.findall(".//context"):
            ctx_id = ctx.get("id")
            if not ctx_id: continue
            dims = DimensionManager.extract_dimensions(ctx)
            if dims: context_dims[ctx_id] = dims
            
            period = ctx.find("period")
            if period is not None:
                date_elem = period.find("endDate") or period.find("instant")
                if date_elem is not None and date_elem.text:
                    d_str = date_elem.text.strip()
                    ctx_date_map[ctx_id] = d_str
                    date_counts[d_str] += 1
        
        if not date_counts: return {}, {}
        
        cy_date_str = date_counts.most_common(1)[0][0]
        try: cy_dt = datetime.strptime(cy_date_str, "%Y-%m-%d")
        except: return {}, {}

        valid_periods = {"CY": cy_date_str}
        for d_str in sorted(date_counts.keys(), reverse=True):
            if d_str == cy_date_str: continue
            try:
                d_dt = datetime.strptime(d_str, "%Y-%m-%d")
                if (cy_dt - d_dt).days >= 300:
                    label = "PY" if round((cy_dt - d_dt).days / 365) == 1 else f"PY_{d_str}"
                    valid_periods[label] = d_str
            except: continue
            
        self.period_date_map = valid_periods
        for cid, dstr in ctx_date_map.items():
            for label, p_date in valid_periods.items():
                if dstr == p_date: context_map[cid] = label; break
                
        return context_map, context_dims

    def _extract_facts(self, tree: Any, contexts: Dict[str, str], context_dims: Dict[str, Dict[str, str]], label_mgr: LabelManager) -> List[SemanticFact]:
        facts = []
        for elem in tree.iter():
            ctx_ref = elem.get("contextRef")
            if not ctx_ref or ctx_ref not in contexts: continue
            raw_val = elem.text
            if not raw_val or not any(char.isdigit() for char in raw_val): continue
            
            clean_str = raw_val.strip()
            if re.match(r'^\d{4}-\d{2}-\d{2}$', clean_str): continue
            if re.match(r'^(19|20)\d{2}$', clean_str): continue

            dec_int = int(elem.get("decimals")) if elem.get("decimals") not in ('INF', 'None', None) else None
            unit_type = UnitManager.detect_unit_type(elem.get("unitRef", "USD"), elem.tag)
            
            # v16.0 Spoke B: Confidence Scoring from ScaleProcessor
            val, tag, conf_score = ScaleProcessor.apply_self_healing(raw_val, dec_int, unit_type)
            
            final_label = label_mgr.get_label(elem.tag) or elem.tag
            # [Step 3] Use .lab map if available
            if elem.tag in self.label_map:
                final_label = self.label_map[elem.tag]
            
            dims = context_dims.get(ctx_ref, {})
            if dims: final_label += f" ({', '.join([f'{k}:{v}' for k,v in dims.items()])})"

            facts.append(SemanticFact(
                concept=elem.tag, 
                label=final_label, 
                value=val, 
                raw_value=raw_val, 
                unit=unit_type, 
                period=contexts[ctx_ref], 
                context_ref=ctx_ref, 
                decimals=dec_int, 
                is_consolidated=True, 
                dimensions=dims,
                confidence_score=conf_score
            ))
            if tag != "raw_pass":
                facts[-1].tags.append(tag)
        return facts
