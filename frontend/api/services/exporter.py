"""
FinDistill Multi-Format Exporter

Exports normalized financial data to:
- JSONL: For LLM fine-tuning (instruction-response pairs)
- Markdown: For RAG systems (hierarchical text)
- Parquet: For large-scale analytics (compressed columnar)
"""

import json
import io
from typing import Dict, Any, List
from datetime import datetime


class DataExporter:
    """Exports financial data to various formats for AI training."""
    
    def to_jsonl(self, data: Dict[str, Any]) -> str:
        """
        Convert to JSONL format for LLM fine-tuning.
        Creates instruction-response pairs from the data.
        
        Output format per line:
        {"instruction": "...", "input": "...", "output": "..."}
        """
        lines = []
        
        # Summary instruction
        lines.append(json.dumps({
            "instruction": "다음 재무 문서의 핵심 내용을 요약해주세요.",
            "input": data.get("title", "재무 문서"),
            "output": data.get("summary", "요약 정보 없음")
        }, ensure_ascii=False))
        
        # Table extraction instructions
        for table in data.get("tables", []):
            table_name = table.get("name", "테이블")
            headers = table.get("headers", [])
            rows = table.get("rows", [])
            
            if rows:
                # Create instruction for table understanding
                table_text = self._table_to_text(table)
                lines.append(json.dumps({
                    "instruction": f"다음 '{table_name}' 테이블의 데이터를 분석해주세요.",
                    "input": table_text,
                    "output": f"이 테이블은 {len(headers)}개의 컬럼과 {len(rows)}개의 데이터 행을 포함합니다."
                }, ensure_ascii=False))
                
                # Create Q&A pairs for each row
                for row in rows[:10]:  # Limit to first 10 rows
                    if len(headers) > 0 and len(row) > 0:
                        lines.append(json.dumps({
                            "instruction": f"'{table_name}'에서 '{headers[0]}'이(가) '{row[0]}'인 데이터를 찾아주세요.",
                            "input": table_text,
                            "output": ", ".join([f"{h}: {v}" for h, v in zip(headers, row)])
                        }, ensure_ascii=False))
        
        # Key metrics instructions
        for metric, value in data.get("key_metrics", {}).items():
            lines.append(json.dumps({
                "instruction": f"재무제표에서 {metric}를 추출해주세요.",
                "input": data.get("title", "재무제표"),
                "output": f"{metric}: {value}"
            }, ensure_ascii=False))
        
        return "\n".join(lines)
    
    def to_markdown(self, data: Dict[str, Any]) -> str:
        """
        Convert to Markdown format for RAG systems.
        Creates hierarchical document with proper table formatting.
        """
        md_lines = []
        
        # Title
        title = data.get("title", "재무 문서")
        md_lines.append(f"# {title}")
        md_lines.append("")
        
        # Metadata
        if "metadata" in data:
            md_lines.append("## 문서 정보")
            for key, value in data["metadata"].items():
                md_lines.append(f"- **{key}**: {value}")
            md_lines.append("")
        
        # Summary
        if "summary" in data:
            md_lines.append("## 요약")
            md_lines.append(data["summary"])
            md_lines.append("")
        
        # Key Metrics
        if "key_metrics" in data and data["key_metrics"]:
            md_lines.append("## 핵심 지표")
            md_lines.append("")
            md_lines.append("| 지표 | 값 |")
            md_lines.append("|------|-----|")
            for metric, value in data["key_metrics"].items():
                md_lines.append(f"| {metric} | {value} |")
            md_lines.append("")
        
        # Tables
        for i, table in enumerate(data.get("tables", []), 1):
            table_name = table.get("name", f"테이블 {i}")
            headers = table.get("headers", [])
            rows = table.get("rows", [])
            
            md_lines.append(f"## {table_name}")
            md_lines.append("")
            
            if headers:
                # Header row
                md_lines.append("| " + " | ".join(str(h) for h in headers) + " |")
                md_lines.append("|" + "|".join(["---"] * len(headers)) + "|")
                
                # Data rows
                for row in rows:
                    # Ensure row has same length as headers
                    padded_row = list(row) + [""] * (len(headers) - len(row))
                    md_lines.append("| " + " | ".join(str(v) for v in padded_row[:len(headers)]) + " |")
            
            md_lines.append("")
        
        # Footer
        md_lines.append("---")
        md_lines.append(f"*Generated by FinDistill at {datetime.now().isoformat()}*")
        
        return "\n".join(md_lines)
    
    def to_parquet(self, data: Dict[str, Any]) -> bytes:
        """
        Convert to Parquet format for large-scale analytics.
        Uses PyArrow for efficient columnar storage.
        """
        import pandas as pd
        import pyarrow as pa
        import pyarrow.parquet as pq
        
        # Collect all tables into DataFrames
        dfs = []
        
        for table in data.get("tables", []):
            table_name = table.get("name", "Unknown")
            headers = table.get("headers", [])
            rows = table.get("rows", [])
            
            if headers and rows:
                df = pd.DataFrame(rows, columns=headers)
                df["_source_table"] = table_name
                df["_document_title"] = data.get("title", "Unknown")
                dfs.append(df)
        
        # Add key metrics as a separate "table"
        if data.get("key_metrics"):
            metrics_df = pd.DataFrame([{
                "metric": k,
                "value": str(v),
                "_source_table": "key_metrics",
                "_document_title": data.get("title", "Unknown")
            } for k, v in data["key_metrics"].items()])
            dfs.append(metrics_df)
        
        if not dfs:
            # Create empty DataFrame if no data
            combined = pd.DataFrame({
                "title": [data.get("title", "")],
                "summary": [data.get("summary", "")]
            })
        else:
            # Combine all DataFrames
            combined = pd.concat(dfs, ignore_index=True)
        
        # Convert to Parquet bytes
        buffer = io.BytesIO()
        table = pa.Table.from_pandas(combined)
        pq.write_table(table, buffer, compression='snappy')
        
        return buffer.getvalue()
    
    def _table_to_text(self, table: Dict[str, Any]) -> str:
        """Convert a table to readable text format."""
        lines = []
        headers = table.get("headers", [])
        rows = table.get("rows", [])
        
        if headers:
            lines.append("컬럼: " + ", ".join(str(h) for h in headers))
        
        for i, row in enumerate(rows[:5], 1):  # Limit to 5 rows for context
            lines.append(f"행 {i}: " + ", ".join(str(v) for v in row))
        
        if len(rows) > 5:
            lines.append(f"... 외 {len(rows) - 5}개 행")
        
        return "\n".join(lines)


# Singleton instance
exporter = DataExporter()
